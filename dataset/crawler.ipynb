{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"crawler.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PZ9nb0GwBPWX"},"outputs":[],"source":["from bs4 import *\n","import requests as rq\n","import os"]},{"cell_type":"code","source":["'''\n","r2 = rq.get(\"https://www.airbnb.com.tw/\")\n","soup2 = BeautifulSoup(r2.text,\"html.parser\")\n","\n","links = []\n","\n","x = soup2.find_all(\"div\")\n","print(x)\n","for tag in x:\n","  y = tag.find_all(\"img\")\n","  for img in y:\n","    print(img['src'])\n","\n","\n","print(\"end\")\n","'''\n","!mkdir /content/sample_data/images\n","!mkdir /content/sample_data/process_img"],"metadata":{"id":"T0EDe8rNBjVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import signal\n","from contextlib import contextmanager\n","import os\n","import time\n","import json\n","import requests\n","\n","class TimeoutException(Exception): pass\n","\n","@contextmanager\n","def time_limit(seconds):\n","    def signal_handler(signum, frame):\n","        raise TimeoutException(\"Timed out!\")\n","    signal.signal(signal.SIGALRM, signal_handler)\n","    signal.alarm(seconds)\n","    try:\n","        yield\n","    finally:\n","        signal.alarm(0)\n","\n","def downloadFromURL(imagesURL):\n","    i = 0\n","    for img in imagesURL:  \n","      i += 1\n","      try:\n","        with time_limit(10):\n","          img_data = requests.get(img[1]).content\n","          print(\"saving image {}\".format(i))\n","          with open(\"/content/sample_data/images/{}.jpg\".format(img[0]), 'wb') as handler:\n","            handler.write(img_data)\n","      except TimeoutException as e:\n","        print(\"Timed out!\")      \n","\n","def getManyPages(pages):\n","    params=[]\n","    for i in range(0, 12*pages+12, 12):\n","        params.append({\n","            'resource_id': 28266,\n","            'from_mid': 1,\n","            'format': 'json',\n","            'ie': 'utf-8',\n","            'oe': 'utf-8',\n","            'query': '明星',\n","            'sort_key': '',\n","            'sort_type': 1,\n","            'stat0': '',\n","            'stat1': '',\n","            'stat2': '',\n","            'stat3': '',\n","            'pn': i,\n","            'rn': 12\n","                  })\n","    url = 'https://sp0.baidu.com/8aQDcjqpAAV3otqbppnN2DJv/api.php'\n","    names = []\n","    img_results = []\n","    x = 0\n","    f = open('starName.txt', 'w')\n","    for param in params:\n","        try:\n","            res = requests.get(url, params=param)\n","            js = json.loads(res.text)\n","            results = js.get('data')[0].get('result')\n","        except:\n","            continue\n","        for result in results:\n","            img_name = result['ename']\n","            img_url = result['pic_4n_78']\n","            img_result =  [img_name,img_url]\n","            img_results.append(img_result)\n","            f.write(img_name+'\\n')\n","            #print(img_name+\"\\n\")\n","            names.append(img_name)\n","\n","        if x % 10 == 0:\n","            print('第%d页......'%x)\n","        x += 1\n","    f.close()\n","    #downloadFromURL(img_results)\n","    #for img in img_results:\n","      #print(\"0: \",img[0])\n","      #print(\"1: \",img[1])\n","    downloadFromURL(img_results)  \n","\n","getManyPages(1000)\n","\n"],"metadata":{"id":"WtS5Z6wTPi7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import os\n","\n","\n","def processImage(path,new_path):  \n","  face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n","  for file in os.listdir(path):\n","    print(file)  \n","    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n","      try:\n","        print(file) \n","        img = cv2.imread(\"{}/{}\".format(path,file))\n","        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n","        for (x, y, w, h) in faces:\n","          #cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n","          faces = img[y:y + h, x:x + w]\n","          faces = cv2.resize(faces, (64, 64), interpolation=cv2.INTER_AREA)\n","          cv2.imwrite(\"{}/{}\".format(new_path,file), faces)\n","      except:\n","        continue    \n","      cv2.waitKey()  \n","\n","processImage(path='/content/sample_data/images',new_path='/content/sample_data/process_img')"],"metadata":{"id":"SMxmaduvlCGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install facenet-pytorch"],"metadata":{"id":"Gu9dy9pSgyi6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from facenet_pytorch import MTCNN, InceptionResnetV1\n","from PIL import Image\n","import torch\n","def detectFaceImage(save_count = 5000):\n","  count = 0\n","  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","  mtcnn = MTCNN(\n","    image_size=160, margin=0, min_face_size=20,\n","    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n","    device=device\n","  )\n","  resnet = InceptionResnetV1(pretrained='vggface2').eval()\n","  path = \"/content/sample_data/process_img\"\n","  for file in os.listdir(path):\n","    image_dir = path+\"/\"+file\n","    x = Image.open(image_dir)\n","    x_aligned, prob = mtcnn(x, return_prob=True)\n","    if x_aligned is None:\n","      print(file)\n","      os.remove(image_dir)\n","    else:\n","      print(\"prob :\",prob)\n","      count+=1\n","      if(count >= save_count):\n","          break       \n","\n","detectFaceImage(6000)"],"metadata":{"id":"2c-PLqQ7gn6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get install rar\n","!rar a \"/content/sample_data/celebA_asia.rar\" \"/content/sample_data/process_img\""],"metadata":{"id":"z7ZTa028iGOJ"},"execution_count":null,"outputs":[]}]}