{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"validation_psp.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O9KLPN8rCBB6"},"outputs":[],"source":["!pip install deepface"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8wwsB1ACgZ0","executionInfo":{"status":"ok","timestamp":1641755995127,"user_tz":-480,"elapsed":31148,"user":{"displayName":"何卓耀","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17091933086398837298"}},"outputId":"29691a9e-97ef-4d2d-9869-86d7ff81dd64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#@title Setup Repository\n","import os\n","os.chdir('/content')\n","CODE_DIR = 'encoder4editing'\n","\n","!git clone https://github.com/eladrich/pixel2style2pixel.git $CODE_DIR\n","!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","!sudo unzip ninja-linux.zip -d /usr/local/bin/\n","!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n","os.chdir(f'./{CODE_DIR}')\n","\n","from argparse import Namespace\n","import time\n","import os\n","import sys\n","import numpy as np\n","from PIL import Image\n","import torch\n","import torchvision.transforms as transforms\n","\n","sys.path.append(\".\")\n","sys.path.append(\"..\")\n","\n","from utils.common import tensor2im\n","from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n","\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"IyF8UD-ZH9M3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Select which experiment you wish to perform inference on: { run: \"auto\" }\n","experiment_type = 'unmasked_masked' #@param ['unmasked_masked','ffhq_encode', 'ffhq_frontalize', 'celebs_sketch_to_face', 'celebs_seg_to_face', 'celebs_super_resolution', 'toonify']"],"metadata":{"id":"lQpdh3hUDIwe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Download\n","def get_download_model_command(file_id, file_name):\n","    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n","    current_directory = os.getcwd()\n","    save_path = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n","    if not os.path.exists(save_path):\n","        os.makedirs(save_path)\n","    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n","    return url\n","\n","MODEL_PATHS = {\n","    \"unmasked_masked\" : {\"id\": \"17BKYibSc43zLFZxeyAfsHMBkBE6TG7ml\", \"name\": \"unmasked_masked.pt\"}\n","}\n","\n","path = MODEL_PATHS[experiment_type]\n","download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n","!{download_command}"],"metadata":{"id":"K2QaDcduDNgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EXPERIMENT_DATA_ARGS = {\n","    \"unmasked_masked\": {\n","        \"model_path\": \"pretrained_models/unmasked_masked.pt\",\n","        \"image_path\": \"notebooks/images/input_img.jpg\",\n","        \"transform\": transforms.Compose([\n","            transforms.Resize((256, 256)),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","    }\n","}\n","\n","EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[experiment_type]\n","img_transforms = EXPERIMENT_ARGS['transform']\n","resize_dims = (256, 256)"],"metadata":{"id":"WAaUie78D7mq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = EXPERIMENT_ARGS['model_path']\n","ckpt = torch.load(model_path, map_location='cpu')\n","opts = ckpt['opts']\n","# update the training options\n","opts['checkpoint_path'] = model_path\n","if 'learn_in_w' not in opts:\n","    opts['learn_in_w'] = False\n","if 'output_size' not in opts:\n","    opts['output_size'] = 1024"],"metadata":{"id":"TAOVzNZcE_qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opts = Namespace(**opts)\n","net = pSp(opts)\n","net.eval()\n","net.cuda()\n","print('Model successfully loaded!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8ppncToFJUS","executionInfo":{"status":"ok","timestamp":1641756120144,"user_tz":-480,"elapsed":13526,"user":{"displayName":"何卓耀","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17091933086398837298"}},"outputId":"f474a51d-c791-495f-8c21-a77fa0afdb69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pSp from checkpoint: pretrained_models/unmasked_masked.pt\n","Model successfully loaded!\n"]}]},{"cell_type":"code","source":["def run_on_batch(inputs, net, latent_mask=None):\n","    if latent_mask is None:\n","        result_batch = net(inputs.to(\"cuda\").float(), randomize_noise=False)\n","    else:\n","        result_batch = []\n","        for image_idx, input_image in enumerate(inputs):\n","            # get latent vector to inject into our input image\n","            vec_to_inject = np.random.randn(1, 512).astype('float32')\n","            _, latent_to_inject = net(torch.from_numpy(vec_to_inject).to(\"cuda\"),\n","                                      input_code=True,\n","                                      return_latents=True)\n","            # get output image with injected style vector\n","            res = net(input_image.unsqueeze(0).to(\"cuda\").float(),\n","                      latent_mask=latent_mask,\n","                      inject_latent=latent_to_inject)\n","            result_batch.append(res)\n","        result_batch = torch.cat(result_batch, dim=0)\n","    return result_batch"],"metadata":{"id":"uEzhdcPDGJXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip /content/drive/Shareddrives/AIProject/Dataset/celeba_unmasked_folder.zip -d /content/sample_data\n","!unzip /content/drive/Shareddrives/AIProject/Dataset/celeba_masked_folder.zip -d /content/sample_data"],"metadata":{"id":"dDZ26foiGRiX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","# shutil.rmtree(\"/content/sample_data/result_face\")\n","!mkdir /content/sample_data/result_face"],"metadata":{"id":"lIgmlZcWGTkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_distance(image_name,df):\n","  distance = -1\n","  for i in range(len(df['VGG-Face_cosine'])):\n","    if(image_name == df['identity'][i].split(\"/\")[4] ):\n","      distance = df['VGG-Face_cosine'][i]    \n","\n","  if(distance == -1):\n","    distance = 1\n","\n","  return distance  "],"metadata":{"id":"vZpeexI3GZ7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","#replace file to mute warning\n","from deepface import DeepFace\n","import gdown\n","import os\n","import shutil\n","url = \"https://drive.google.com/u/0/uc?id=1aS5SJCK9MLMyYPXmhAkwtn3cJhQGCbGj&export=download\"\n","gdown.download(url, \"/content/sample_data/DeepFace.py\")\n","os.remove(\"/usr/local/lib/python3.7/dist-packages/deepface/DeepFace.py\")\n","shutil.move(\"/content/sample_data/DeepFace.py\",\"/usr/local/lib/python3.7/dist-packages/deepface/\")\n","'''"],"metadata":{"id":"atufHvBeWRqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.utils import save_image\n","masked_dir = \"/content/sample_data/celeba_masked_folder/\"\n","db_path = \"/content/sample_data/celeba_unmasked_folder\"\n","from deepface import DeepFace\n","count = 0\n","total_accuracy = 0\n","for masked_image_dir in os.listdir(masked_dir):\n","  if not masked_image_dir.endswith(\".ipynb_checkpoints\"):\n","    count += 1\n","    image = Image.open(masked_dir + masked_image_dir)\n","    image = image.convert(\"RGB\")\n","    image = image.resize(resize_dims)\n","    image = img_transforms(image)\n","    with torch.no_grad():\n","      tic = time.time()\n","      images = run_on_batch(image.unsqueeze(0), net,None)\n","      result_image = images[0]\n","      result_image = (result_image+1)/2\n","      result_dir = \"/content/sample_data/result_face/\"+ masked_image_dir\n","      save_image(result_image,result_dir)\n","      toc = time.time()\n","      df = DeepFace.find(img_path=result_dir,db_path=db_path,enforce_detection=False)\n","      accuracy = 1 - calc_distance(masked_image_dir.split(\".\")[0],df)\n","      total_accuracy += accuracy\n","      print(\"masked_image :\",masked_image_dir,\"recognize_image:\",df['identity'][0].split(\"/\")[4],\"Accuracy: \",accuracy)\n","    if(count >= 1000):\n","      break  \n","\n","print(\"Accuracy of Model over {} images is : {}\".format(count,total_accuracy/count))"],"metadata":{"id":"l7zF4JbIGcRg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ffhq psp 0.4820933278986273"],"metadata":{"id":"tuYU-gAcmKv4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shutil.rmtree(\"/content/sample_data/celeba_unmasked_folder\")\n","shutil.rmtree(\"/content/sample_data/celeba_masked_folder\")"],"metadata":{"id":"QCKlGr1tPA6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/sample_data\n","!apt-get install rar\n","!rar a \"pkl.rar\" \"/content/sample_data/ffhq_unmasked_folder\""],"metadata":{"id":"woiZDNLCQ0M0"},"execution_count":null,"outputs":[]}]}