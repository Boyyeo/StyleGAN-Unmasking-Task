{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"validation_e4e.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uuXjcr_PAMb-"},"outputs":[],"source":["!pip install deepface\n","#import os\n","#import shutil\n","import gdown"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ZvpHlHzqAfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641755561108,"user_tz":-480,"elapsed":15847,"user":{"displayName":"姚呈宇","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07230018011644714863"}},"outputId":"58af720f-a70d-4ee5-adeb-28da9d496797"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#@title Setup Repository\n","import os\n","os.chdir('/content')\n","CODE_DIR = 'encoder4editing'\n","\n","!git clone https://github.com/omertov/encoder4editing.git $CODE_DIR\n","!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","!sudo unzip ninja-linux.zip -d /usr/local/bin/\n","!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n","os.chdir(f'./{CODE_DIR}')\n","\n","from argparse import Namespace\n","import time\n","import os\n","import sys\n","import numpy as np\n","from PIL import Image\n","import torch\n","import torchvision.transforms as transforms\n","\n","sys.path.append(\".\")\n","sys.path.append(\"..\")\n","\n","from utils.common import tensor2im\n","from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n","\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"cellView":"form","id":"P2GQlKDGA6qk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Download\n","def get_download_model_command(file_id, file_name):\n","    \"\"\" Get wget download command for downloading the desired model and save to directory pretrained_models. \"\"\"\n","    current_directory = os.getcwd()\n","    save_path = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n","    if not os.path.exists(save_path):\n","        os.makedirs(save_path)\n","    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n","    return url   \n","\n","MODEL_PATHS = {\n","     \"unmasked_masked\": {\"id\": \"1eNyb7FyrV0yTjYBL0FKdwN2fqG_2-zRt\", \"name\": \"e4e_unmasked_masked.pt\"},\n","}    \n","\n","path = MODEL_PATHS[\"unmasked_masked\"]\n","download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"]) \n","\n","!wget {download_command}"],"metadata":{"id":"_ctIgkenBEws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup required image transformations\n","EXPERIMENT_DATA_ARGS = {\n","    \"unmasked_masked\": {\n","        \"model_path\": \"pretrained_models/e4e_unmasked_masked.pt\",\n","        \"image_path\": \"notebooks/images/1.png\"\n","    }}\n","EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[\"unmasked_masked\"]\n","EXPERIMENT_ARGS['transform'] = transforms.Compose([\n","                              transforms.Resize((256, 256)),\n","                              transforms.ToTensor(),\n","                              transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","resize_dims = (256, 256)\n","img_transforms = EXPERIMENT_ARGS['transform']"],"metadata":{"id":"u0vBlAGlBNFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = EXPERIMENT_ARGS['model_path']\n","ckpt = torch.load(model_path, map_location='cpu')\n","opts = ckpt['opts']\n","# pprint.pprint(opts)  # Display full options used\n","# update the training options\n","opts['checkpoint_path'] = model_path\n","opts= Namespace(**opts)\n","net = pSp(opts)\n","net.eval()\n","net.cuda()\n","print('Model successfully loaded!')"],"metadata":{"id":"L3MiTk_wBIhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_alongside_source_image(result_image, source_image):\n","    res = np.concatenate([np.array(source_image.resize(resize_dims)),\n","                          np.array(result_image.resize(resize_dims))], axis=1)\n","    return Image.fromarray(res)\n","\n","def run_on_batch(inputs, net):\n","    images, latents = net(inputs.to(\"cuda\").float(), randomize_noise=False, return_latents=True)\n","    #if experiment_type == 'cars_encode':\n","        #images = images[:, :, 32:224, :]\n","    return images, latents"],"metadata":{"id":"h6ASnmPpBPIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#replace file to mute warning\n","#import gdown\n","import shutil\n","url = \"https://drive.google.com/u/0/uc?id=1aS5SJCK9MLMyYPXmhAkwtn3cJhQGCbGj&export=download\"\n","gdown.download(url, \"/content/sample_data/DeepFace.py\")\n","os.remove(\"/usr/local/lib/python3.7/dist-packages/deepface/DeepFace.py\")\n","shutil.move(\"/content/sample_data/DeepFace.py\",\"/usr/local/lib/python3.7/dist-packages/deepface/\")"],"metadata":{"id":"38L0U6dmFtce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip /content/drive/Shareddrives/AIProject/Dataset/AAFD_test_unmasked_folder.zip -d /content/sample_data\n","!unzip /content/drive/Shareddrives/AIProject/Dataset/AAFD_test_masked_folder.zip -d /content/sample_data"],"metadata":{"id":"HDDq7ip8F9Dd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df['VGG-Face_cosine'][0]\n","#00131.png\n","#masked  -----  0.3056197013748233\n","#predicted ----  0.261993\n","#ground_truth -  9.992007e-16\n","!mkdir /content/sample_data/result_face"],"metadata":{"id":"XBHnDN6kJGId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_distance(image_name,df):\n","  distance = -1\n","  for i in range(len(df['VGG-Face_cosine'])):\n","    if(image_name == df['identity'][i].split(\"/\")[4] ):\n","      distance = df['VGG-Face_cosine'][i]    \n","\n","  if(distance == -1):\n","    distance = 1\n","\n","  return distance  "],"metadata":{"id":"mjUzLFeFboZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall deepface\n","!pip install deepface\n","from deepface import DeepFace\n","import gdown"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"6hwlBfkDSA-k","executionInfo":{"status":"ok","timestamp":1641756072825,"user_tz":-480,"elapsed":382,"user":{"displayName":"姚呈宇","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07230018011644714863"}},"outputId":"66655701-19a0-49c2-d030-6952ffe37452"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing collected packages: deepface\n","Successfully installed deepface-0.0.70\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["deepface"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Directory  /root /.deepface created\n","Directory  /root /.deepface/weights created\n"]}]},{"cell_type":"code","source":["from torchvision.utils import save_image\n","#from deepface import DeepFace\n","masked_dir = \"/content/sample_data/AAFD_test_masked_folder/\"\n","db_path = \"/content/sample_data/AAFD_test_unmasked_folder\"\n","count = 0\n","total_accuracy = 0\n","for masked_image_dir in os.listdir(masked_dir):\n","  if not masked_image_dir.endswith(\".ipynb_checkpoints\"):\n","    count += 1\n","    image = Image.open(masked_dir + masked_image_dir)\n","    image = image.convert(\"RGB\")\n","    image = image.resize(resize_dims)\n","    image = img_transforms(image)\n","    with torch.no_grad():\n","      tic = time.time()\n","      images, latents = run_on_batch(image.unsqueeze(0), net)\n","      result_image, latent = images[0], latents[0]\n","      result_image = (result_image+1)/2\n","      result_dir = \"/content/sample_data/result_face/\"+ masked_image_dir\n","      save_image(result_image,result_dir)\n","      toc = time.time()\n","      df = DeepFace.find(img_path=result_dir,db_path=db_path,enforce_detection=False)\n","      accuracy = 1 - calc_distance(masked_image_dir.split(\".\")[0],df)\n","      total_accuracy += accuracy\n","      print(\"masked_image :\",masked_image_dir,\"recognize_image:\",df['identity'][0].split(\"/\")[4],\"Accuracy: \",accuracy)\n","    if(count >= 1000):\n","      break  \n","\n","print(\"Accuracy of Model over {} images is : {}\".format(count,total_accuracy/count))"],"metadata":{"id":"vMa-eN3vM_yv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#celeba e4e 0.13463303921646666"],"metadata":{"id":"gCRxygunOMZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"lFcHE4XzYTfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.utils import save_image\n","def unmasked_image(path):\n","  #read image\n","  image = Image.open(\"/content/sample_data/ffhq_validation_set/masked/\"+path)\n","  image = image.convert(\"RGB\")\n","  #transform first\n","  image = image.resize(resize_dims)\n","  image = img_transforms(image)\n","  #unmasked now\n","  with torch.no_grad():\n","    tic = time.time()\n","    images, latents = run_on_batch(image.unsqueeze(0), net)\n","    result_image, latent = images[0], latents[0]\n","    result_image = (result_image+1)/2\n","    save_image(result_image,\"/content/sample_data/result_face/\"+path)\n","    toc = time.time()\n","    print('Inference took {:.4f} seconds.'.format(toc - tic))\n","\n","unmasked_image(\"00132.png\")    "],"metadata":{"id":"gLFXARpJBQ4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unmasked_image()"],"metadata":{"id":"Bg4FZcU0BX00"},"execution_count":null,"outputs":[]}]}